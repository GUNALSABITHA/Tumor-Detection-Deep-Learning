{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 2236708,
     "sourceType": "datasetVersion",
     "datasetId": 1343913
    }
   ],
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip uninstall tensorflow tensorflow-estimator tensorflow-io-gcs-filesystem keras --yes"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!pip cache purge"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install tensorflow==2.15.0"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "print(keras.__version__)\n",
    "print(tf.__version__)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-24T11:51:08.752219Z",
     "iopub.execute_input": "2024-03-24T11:51:08.752720Z",
     "iopub.status.idle": "2024-03-24T11:51:16.407053Z",
     "shell.execute_reply.started": "2024-03-24T11:51:08.752683Z",
     "shell.execute_reply": "2024-03-24T11:51:16.405150Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "text": "2024-03-24 11:51:09.338404: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-24 11:51:09.338514: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-24 11:51:09.340335: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "2.15.0\n2.15.0\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import zipfile\n",
    "import math\n",
    "import shutil\n",
    "import glob\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from PIL import Image"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!cp -r /kaggle/input/brian-tumor-dataset /kaggle/working"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import shutil\n",
    "\n",
    "def create_data_directory(DEST_ROOT, ROOT_DIR, type='train', size=1):\n",
    "    \"\"\"\n",
    "    This function creates the directory for the given type of data, like train, test and validation.\n",
    "    :param DEST_ROOT: The destination root directory of the data, usually the 'data' directory.\n",
    "    :param ROOT_DIR: The root directory of the data.\n",
    "    :param type: The type of data like train, test and validation.\n",
    "    :param size: The size of the data in the directory like 0.7, 0.2 and 0.1.\n",
    "    :return: A directory for the given type of data.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(os.path.join(ROOT_DIR)):\n",
    "        print(f\"The source directory {ROOT_DIR} does not exist.\")\n",
    "        return\n",
    "\n",
    "    number_of_images = {}\n",
    "\n",
    "    for i in os.listdir(ROOT_DIR):\n",
    "        number_of_images[i] = len(os.listdir(os.path.join(ROOT_DIR, i)))\n",
    "\n",
    "    dest_dir = os.path.join(DEST_ROOT, type)\n",
    "\n",
    "    if not os.path.exists(dest_dir):\n",
    "        try:\n",
    "            os.makedirs(dest_dir)\n",
    "        except PermissionError:\n",
    "            print(f\"Permission denied: Could not create directory {dest_dir}\")\n",
    "            return\n",
    "\n",
    "        for dir in os.listdir(ROOT_DIR):\n",
    "            new_dir = os.path.join(dest_dir, dir)\n",
    "\n",
    "            try:\n",
    "                os.makedirs(new_dir)\n",
    "            except PermissionError:\n",
    "                print(f\"Permission denied: Could not create directory {new_dir}\")\n",
    "                return\n",
    "\n",
    "            images = os.listdir(os.path.join(ROOT_DIR, dir))\n",
    "            np.random.shuffle(images)\n",
    "\n",
    "            # Get the number of images for the given type of data as per the size parameter..\n",
    "            size_dir = math.floor(number_of_images[dir] * size)\n",
    "\n",
    "            # Move the images to the given type of data directory.\n",
    "            for image in images[:size_dir]:\n",
    "                src = os.path.join(ROOT_DIR, dir, image)\n",
    "                dest = os.path.join(new_dir, image)\n",
    "\n",
    "                if os.path.exists(src) and not os.path.exists(dest):\n",
    "                    try:\n",
    "                        shutil.move(src, dest)\n",
    "                    except PermissionError:\n",
    "                        print(f\"Permission denied: Could not move file {src} to {dest}\")\n",
    "                        return\n",
    "                else:\n",
    "                    print(f\"File {src} does not exist or file {dest} already exists.\")\n",
    "    else:\n",
    "        print(f\"The directory {type} already exists in {DEST_ROOT}\")"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "create_data_directory('data', \"/kaggle/working/brian-tumor-dataset/Brain Tumor Data Set/Brain Tumor Data Set\", \"test\", 0.15)\n",
    "print(f\"The test directory has been created with {len(os.listdir('data/test'))} subdirectories.\")\n",
    "create_data_directory('data', \"/kaggle/working/brian-tumor-dataset/Brain Tumor Data Set/Brain Tumor Data Set\", \"val\", 0.15)\n",
    "print(f\"The val directory has been created with {len(os.listdir('data/val'))} subdirectories.\")\n",
    "create_data_directory('data', \"/kaggle/working/brian-tumor-dataset/Brain Tumor Data Set/Brain Tumor Data Set\", \"train\")\n",
    "print(f\"The train directory has been created with {len(os.listdir('data/train'))} subdirectories.\")"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "len(os.listdir('data/train/Brain Tumor')) + len(os.listdir('data/train/Healthy'))"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "len(os.listdir('data/val/Brain Tumor')) + len(os.listdir('data/val/Healthy'))"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "len(os.listdir('data/test/Brain Tumor')) + len(os.listdir('data/test/Healthy'))"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, BatchNormalization, Dropout, GlobalAvgPool2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "import tensorflow.keras as keras"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "strategy = tf.distribute.MirroredStrategy()"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "with strategy.scope():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters=16,kernel_size=(3,3),activation=\"relu\",input_shape=(224,224,3), padding='same'))\n",
    "\n",
    "    model.add(Conv2D(filters=32,kernel_size=(3,3),activation=\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(filters=64,kernel_size=(3,3),activation=\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(filters=128,kernel_size=(3,3),activation=\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Dropout(rate=0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=64,activation='relu'))\n",
    "    model.add(Dropout(rate=0.25))\n",
    "    model.add(Dense(units=1,activation='sigmoid'))\n",
    "    \n",
    "    # Use AdamW optimizer\n",
    "    model.compile(optimizer=tf.keras.optimizers.AdamW(learning_rate=1e-4),loss=keras.losses.binary_crossentropy)"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dir(ImageDataGenerator)"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def preprocessing_images(path):\n",
    "    \"\"\"\n",
    "    Returns a ImageDataGenerator object.\n",
    "    \"\"\"\n",
    "    image_data = ImageDataGenerator(\n",
    "        zoom_range=0.2,\n",
    "        rescale=1./255,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "    \n",
    "    images = image_data.flow_from_directory(\n",
    "        directory=path,\n",
    "        target_size=(224,224),\n",
    "        class_mode=\"binary\",\n",
    "        shuffle=True,\n",
    "        classes=[\"Brain Tumor\",\"Healthy\"]\n",
    "    )\n",
    "    \n",
    "    return images"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_data = preprocessing_images(\"data/train\")\n",
    "test_data = preprocessing_images(\"data/test\")\n",
    "val_data = preprocessing_images(\"data/val\")"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger, ProgbarLogger, LearningRateScheduler"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "earlystopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.1,\n",
    "    patience=200,\n",
    "    verbose=1,\n",
    "    start_from_epoch=50,\n",
    "    mode = 'min'\n",
    ")\n",
    "\n",
    "modelcheckpoint = ModelCheckpoint(\n",
    "    filepath=\"final_model.keras\",\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "logger = CSVLogger(\n",
    "    filename=\"performance.csv\",\n",
    "    append=True\n",
    ")\n",
    "\n",
    "pbloader = ProgbarLogger()"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "callbacks = [earlystopping,modelcheckpoint,logger,pbloader]"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Training the model\n",
    "history = model.fit(\n",
    "\n",
    "train_data,\n",
    "steps_per_epoch=8,\n",
    "epochs=1500,\n",
    "verbose=1,\n",
    "validation_data=val_data,\n",
    "validation_steps=16,\n",
    "callbacks=callbacks\n",
    ")"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "perf = pd.read_csv(\"/kaggle/working/performance.csv\")"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import keras\n",
    "print(keras.__version__)"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(\"/kaggle/working/final_model.keras\")"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "img = load_img(\"/kaggle/working/data/test/Healthy/Not Cancer  (1426).jpg\")\n",
    "\n",
    "arr = img_to_array(img)\n",
    "\n",
    "arr.shape"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dir(ImageDataGenerator)"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "help(ImageDataGenerator)"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def preprocessing_images(path):\n",
    "    \"\"\"\n",
    "    Returns a ImageDataGenerator object.\n",
    "    \"\"\"\n",
    "    image_data = ImageDataGenerator(\n",
    "        zoom_range=0.2,\n",
    "        rescale=1./255,\n",
    "        horizontal_flip=True,\n",
    "#         target_size=(224,224)\n",
    "    )\n",
    "    \n",
    "    return image_data.shape"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "image = keras.preprocessing.image.load_img(\"/kaggle/working/data/test/Healthy/Not Cancer  (1426).jpg\")"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "image = image.resize((224,224))\n",
    "image"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "path = \"/kaggle/input/brian-tumor-dataset/Brain Tumor Data Set/Brain Tumor Data Set/Brain Tumor/Cancer (1006).jpg\"\n",
    "\n",
    "image = Image.open(path)\n",
    "image = image.resize((224, 224))  # Resize the image\n",
    "\n",
    "# Convert the PIL Image to a NumPy array before reshaping\n",
    "image_array = np.array(image)\n",
    "\n",
    "# Expand dimension if grayscale (assuming it is)\n",
    "if len(image_array.shape) == 2:\n",
    "    image_array = image_array.reshape((224, 224, 1))\n",
    "\n",
    "# Convert from uint8 (0-255) to float32 (0.0-1.0) for the model\n",
    "image_array = image_array.astype('float32') / 255.0\n",
    "\n",
    "# Add a new axis for batch size (even if 1)\n",
    "# model.predict(image_array[np.newaxis])\n",
    "threshold = 0.5  # You can adjust this based on model confidence\n",
    "\n",
    "prediction = model.predict(image_array[np.newaxis])  # Make prediction\n",
    "classification = 1 if prediction[0][0] > threshold else 0  # Apply threshold\n",
    "\n",
    "# Print the classification result (0 - Brain Tumor, 1 - Healthy)\n",
    "print(\"Predicted Class:\", classification)\n"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.predict(arr)"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.predict(arr)"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df.drop('epoch', axis=1).plot()"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
